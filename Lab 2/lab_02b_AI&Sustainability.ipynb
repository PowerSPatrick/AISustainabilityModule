{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2L6NvF1eVojz"
   },
   "source": [
    "# Lab 02.b - Week 3\n",
    "## Early Fire Detection with Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpJcrxnlV5f5"
   },
   "source": [
    "## **Challenge 01**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VVM0Z92V5ny"
   },
   "source": [
    "First, we'll load the saved NumPy array data from the last lab and redefine our auxiliary functions.\n",
    "\n",
    "Please complete the sections  indicated with `TODO X `comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwDZ-wl0WO4Y"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# TODO 01  - Load the data from LAB 01\n",
    "\n",
    "save_path =...\n",
    "X = ...\n",
    "X_test = ...\n",
    "y = ...\n",
    "y_test = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nTiecsVAWXwv"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#TODO 02 - Define our function to Plot the trainig accuracy and Loss\n",
    "\n",
    "def Plot_acc_loss(history):\n",
    "  acc = ...\n",
    "  val_acc = ...\n",
    "\n",
    "  loss = ...\n",
    "  val_loss = ...\n",
    "\n",
    "  epochs_range = range(len(loss))\n",
    "\n",
    "  plt.figure(figsize=(8, 8))\n",
    "  plt.subplot(2, 1, 1)\n",
    "  plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "  plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.title('Training and Validation Accuracy')\n",
    "\n",
    "  plt.subplot(2, 1, 2)\n",
    "  plt.plot(epochs_range, loss, label='Training Loss')\n",
    "  plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "  plt.legend(loc='upper right')\n",
    "  plt.title('Training and Validation Loss')\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6i2VWl0YR5r"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "#TODO 03 - Complete the function to calculate and display the classification metrics and the confusion matrix for the model's predictions.\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "  cm = confusion_matrix(..., ...)\n",
    "\n",
    "  # Define class labels\n",
    "  class_labels = [..., ...]\n",
    "\n",
    "  # Create a DataFrame\n",
    "  cm_df = pd.DataFrame(cm, index=class_labels, columns=class_labels)\n",
    "\n",
    "  plt.figure(figsize=(8,6))\n",
    "  sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "  plt.ylabel('Actual')\n",
    "  plt.xlabel('Predicted')\n",
    "  plt.title('Confusion Matrix')\n",
    "  plt.show()\n",
    "plot_confusion_matrix(..., ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yaR1RoWcWgDq"
   },
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# TODO 04 - Define our image viewing function.\n",
    "reverse_label_map = {\n",
    "  ...\n",
    "}\n",
    "def view_grid_figures(predictions):\n",
    "  combined_list = list(zip(...))\n",
    "  Samples = ...\n",
    "\n",
    "  total_images = 16\n",
    "  grid_size = (4,4)\n",
    "\n",
    "  fig, axes = plt.subplots(grid_size[0], grid_size[1])\n",
    "  axes = axes.flatten()\n",
    "\n",
    "  for idx in range(total_images):\n",
    "      ax = axes[idx]\n",
    "      ax.axis('off')\n",
    "\n",
    "\n",
    "      img = ...\n",
    "      label = ...\n",
    "      ax.imshow(img)\n",
    "\n",
    "      ax.set_title(..., fontsize=10)\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "# ---------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dT4A74sU1PNd"
   },
   "source": [
    "## **Challenge 02**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFV24Y_nWYtV"
   },
   "source": [
    "\n",
    "Can we enhance the performance by using a Convolutional Neural Network (CNN), which is well-suited for image data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "wflG-gTb1ch6",
    "outputId": "9fe0d0d0-7da5-4e06-955a-34e82d161f28"
   },
   "outputs": [],
   "source": [
    "#TODO 01 - Let’s build our CNN model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "input_shape = ...\n",
    "\n",
    "model = Sequential([\n",
    "    Input(input_shape),\n",
    "      Conv2D(...),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')  # Use a single output neuron with a sigmoid activation function for binary classification in the CNN model.\n",
    "])\n",
    "\n",
    "# Display the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YuGDjQZC2GIe"
   },
   "outputs": [],
   "source": [
    "#TODO 02 - Let’s compile our CNN model.\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOLf0K-q2FMH",
    "outputId": "a23841dd-8ddc-40e4-98c4-f58c9a52465e"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "#TODO 03 - Let’s train our CNN model.\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(\"Training Time (s): \", training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "pX2CjfHk2ydU",
    "outputId": "740c1517-d3dd-4570-fe88-7492ac0caf68"
   },
   "outputs": [],
   "source": [
    "#TODO 04 - Evaluate the accuracy and loss graphs to analyse the model’s training progress and identify potential overfitting or underfitting.\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "97KdZb4X2wJ_",
    "outputId": "8db0e129-e43a-4cae-bbaf-475327e7deae"
   },
   "outputs": [],
   "source": [
    "\n",
    "#TODO 05 - Evaluate the classification report.\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jw0mqhBn3V08"
   },
   "outputs": [],
   "source": [
    "#TODO 05 - Plot the confusion matrix to visualise the distribution of correct and incorrect predictions.\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rp1HnS9j3fUN"
   },
   "outputs": [],
   "source": [
    "#TODO 05 - Plot the images along with their true and predicted labels to visually assess the model's performance.\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7eblXKAvlXX"
   },
   "source": [
    "Analysing Model Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RmYPFm_Yvkp4",
    "outputId": "684d18bd-c2dd-4811-ff3c-b60eb7585790"
   },
   "outputs": [],
   "source": [
    "inference_times = []\n",
    "\n",
    "# Perform inference and record times\n",
    "for i in range(len(X_test)):\n",
    "    start_time = time.time()\n",
    "    _ = model.predict(np.array([X_test[i,:,:,:]]), verbose=0)\n",
    "    end_time = time.time()\n",
    "    inference_times.append(end_time - start_time)\n",
    "\n",
    "# Calculate average and standard deviation\n",
    "avg_time = np.mean(inference_times)\n",
    "std_time = np.std(inference_times)\n",
    "\n",
    "print(f\"Training Time: {training_time} s\")\n",
    "print(f'Average Inference Time over {len(X_test)} runs: {avg_time*1000:.2f} ms')\n",
    "print(f'Standard Deviation: {std_time*1000:.2f} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOnNaqmi3jeV",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Did the model improve? Can you improve it further?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bO8mwRDS3rot"
   },
   "source": [
    "## **Challenge 06**\n",
    "### Use the learnt techniques to create a new model that outperforms the prior ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nd4ixnsM37Z1"
   },
   "source": [
    "*Tip Try combining both models.\n",
    "\n",
    "Test different parameters.\n",
    "\n",
    "Try adding more convolutional blocks."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
