{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETMI93kcUveq"
   },
   "source": [
    "# Lab 02.a - Week 3\n",
    "## Early Fire Detection with Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QnkeXhTU1O6"
   },
   "source": [
    "## **Challenge 01**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPFY7O47U2cr"
   },
   "source": [
    "First, let's load the saved NumPy array data from your previous lab and complete the sections marked with `TODO X` comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kx2BhSBVA0o"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# TODO 01  - Load the data from LAB 01\n",
    "\n",
    "save_path =...\n",
    "X = np.load(...)\n",
    "X_test = np.load(...)\n",
    "y = np.load(...)\n",
    "y_test = np.load(...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JlrVSfzrPac"
   },
   "source": [
    "## **Challenge 02**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEWOXfLNrQXu"
   },
   "source": [
    "Now, let’s build our multi-layer perceptronmodel to detect wildfires!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "fVLP85ZarnFC",
    "outputId": "cc0b6e4f-a530-49fe-a199-b349996d8045"
   },
   "outputs": [],
   "source": [
    "#TODO 01 - Let’s begin with a simple Multi-Layer Perceptron (MLP) model.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "input_shape = ...\n",
    "\n",
    "model = Sequential([\n",
    "    Input(input_shape),\n",
    "    Flatten(),\n",
    "    Dense(...),\n",
    "    Dense(1, activation='sigmoid')  # Use a single output neuron with a sigmoid activation function for binary classification.\n",
    "])\n",
    "\n",
    "# Display the model architecture to visualise its layers and parameters.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MV_c4axornLy"
   },
   "outputs": [],
   "source": [
    "#TODO 02 - Let’s compile our MLP model with an appropriate loss function, optimizer, and evaluation metrics.\n",
    "\n",
    "model.compile(\n",
    "    optimizer=...,\n",
    "    loss=...,  # Use a loss function compatible with binary classification problems.\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hto2r8q8rnST",
    "outputId": "bf17725c-1cdc-4008-b560-269997af758f"
   },
   "outputs": [],
   "source": [
    "#TODO 03 - Let’s train our MLP model using the training data while monitoring its performance on the validation set.\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    ..., ..., # Training Data\n",
    "    epochs=...,\n",
    "    batch_size=...,\n",
    "    validation_split=...,  # Use 20% of the training data as a validation set\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(\"Training Time (s): \", training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PXzptcYrlCW3",
    "outputId": "cdad6657-8fe0-4405-a380-2fd4e25e8ee8"
   },
   "outputs": [],
   "source": [
    "#TODO 04 - Evaluate the MLP model on the test data to assess its performance.\n",
    "model.evaluate(..., ...) # Evaluate the model using data that it has never seen before to ensure an unbiased assessment of its generalisation ability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1Vai1AHwGnY"
   },
   "source": [
    "Let’s visualise the training and validation curves to assess the model's performance. Analyse the curves to determine if there is overfitting or underfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "137heBD8v-3r",
    "outputId": "420d3bec-2873-4af4-dbb8-2ee70554f1b7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Plot_acc_loss(history):\n",
    "  acc = history.history['accuracy']\n",
    "  val_acc = history.history['val_accuracy']\n",
    "\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs_range = range(len(loss))\n",
    "\n",
    "  plt.figure(figsize=(8, 8))\n",
    "  plt.subplot(2, 1, 1)\n",
    "  plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "  plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.title('Training and Validation Accuracy')\n",
    "\n",
    "  plt.subplot(2, 1, 2)\n",
    "  plt.plot(epochs_range, loss, label='Training Loss')\n",
    "  plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "  plt.legend(loc='upper right')\n",
    "  plt.title('Training and Validation Loss')\n",
    "  plt.show()\n",
    "Plot_acc_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TTwgiICv1S7"
   },
   "source": [
    "Now, let’s evaluate our model using classification metrics such as accuracy, precision, recall, and F1-score to gain deeper insights into its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZMepS2OGxGX8",
    "outputId": "259e3aa6-d2ea-4063-d3ae-95c8390e1140"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "pred = model.predict(X_test)\n",
    "binary_predictions = [1 if p > 0.5 else 0 for p in pred]\n",
    "\n",
    "\n",
    "print(classification_report(y_test, binary_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GWzTT4UzSJN"
   },
   "source": [
    "And let’s analyse the confusion matrix to understand the model's performance in correctly and incorrectly classifying each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "jC748ivPyimS",
    "outputId": "42f997fe-322f-48e8-d265-a628a3290e82"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "#TODO 05 - Complete the function to calculate and display the classification metrics and the confusion matrix for the model's predictions.\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "  cm = confusion_matrix(..., ...)\n",
    "\n",
    "  # Define class labels\n",
    "  class_labels = [..., ...]\n",
    "\n",
    "  # Create a DataFrame\n",
    "  cm_df = pd.DataFrame(cm, index=class_labels, columns=class_labels)\n",
    "\n",
    "  plt.figure(figsize=(8,6))\n",
    "  sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "  plt.ylabel('Actual')\n",
    "  plt.xlabel('Predicted')\n",
    "  plt.title('Confusion Matrix')\n",
    "  plt.show()\n",
    "plot_confusion_matrix(..., ...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7c1p72zNz_Dc"
   },
   "source": [
    "Finally, let’s visualise the images along with their predicted and true labels to better understand the model’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "hpQ49L7IwNWH",
    "outputId": "a13b08a4-bc4a-46bc-9000-d423b11c2e4b"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "reverse_label_map = {\n",
    "    0:\"Fire\",1:\"Non_Fire\"\n",
    "}\n",
    "def view_grid_figures(predictions):\n",
    "  combined_list = list(zip(X_test, predictions))\n",
    "  Samples = random.sample(combined_list, 16)\n",
    "\n",
    "  total_images = 16\n",
    "  grid_size = (4,4)\n",
    "\n",
    "  fig, axes = plt.subplots(grid_size[0], grid_size[1])\n",
    "  axes = axes.flatten()\n",
    "\n",
    "  for idx in range(total_images):\n",
    "      ax = axes[idx]\n",
    "      ax.axis('off')\n",
    "\n",
    "\n",
    "      img = Samples[idx][0]\n",
    "      label = Samples[idx][1]\n",
    "      ax.imshow(img)\n",
    "\n",
    "      ax.set_title(reverse_label_map[label], fontsize=10)\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "view_grid_figures(binary_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0d5svqbuFVx"
   },
   "source": [
    "Analysing Model Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uJ83sKkNuVBQ",
    "outputId": "684d18bd-c2dd-4811-ff3c-b60eb7585790"
   },
   "outputs": [],
   "source": [
    "inference_times = []\n",
    "\n",
    "# Perform inference and record times\n",
    "for i in range(len(X_test)):\n",
    "    start_time = time.time()\n",
    "    _ = model.predict(np.array([X_test[i,:,:,:]]), verbose=0)\n",
    "    end_time = time.time()\n",
    "    inference_times.append(end_time - start_time)\n",
    "\n",
    "# Calculate average and standard deviation\n",
    "avg_time = np.mean(inference_times)\n",
    "std_time = np.std(inference_times)\n",
    "\n",
    "print(f\"Training Time: {training_time} s\")\n",
    "print(f'Average Inference Time over {len(X_test)} runs: {avg_time*1000:.2f} ms')\n",
    "print(f'Standard Deviation: {std_time*1000:.2f} ms')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
